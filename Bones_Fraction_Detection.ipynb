{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katiasioufii/Bones_fracrion/blob/main/Bones_Fraction_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P74FdOJfFFCM"
      },
      "source": [
        "# ðŸ˜ŠBones Fraction Detection Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd9QTcrLF1kb"
      },
      "source": [
        "###Importing the required Libraries ðŸ“š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "678ISa_MGABK",
        "outputId": "96687513-2a22-4d41-bd0c-479030c42f31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.130)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "!pip install opencv-python\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "!pip install ultralytics\n",
        "from ultralytics import YOLO\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import albumentations as A\n",
        "from PIL import Image\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Jm272P9FtGY"
      },
      "source": [
        "###Download the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbtAhCS0JHOb",
        "outputId": "51e07fab-ae11-4d16-cfae-7028a4333dee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfTjoJ_YKEDM"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgeYoWoPKFpk",
        "outputId": "b6099752-3fd8-4684-c1fd-556754f11be5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['README.dataset.txt', 'data.yaml', 'train', 'valid', 'test']\n",
            "['labels', 'images']\n",
            "['labels', 'images']\n",
            "['labels', 'images']\n"
          ]
        }
      ],
      "source": [
        "print(os.listdir(dataset_path))\n",
        "print(os.listdir(os.path.join(dataset_path, 'train')))\n",
        "print(os.listdir(os.path.join(dataset_path, 'test')))\n",
        "print(os.listdir(os.path.join(dataset_path, 'valid')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhoGAjGLIEGC"
      },
      "source": [
        "###Image preproccing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ysJXP30ICvv"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    img = clahe.apply(img)\n",
        "\n",
        "    # Gaussian Blur\n",
        "    img = cv2.GaussianBlur(img, (5,5), 0)\n",
        "\n",
        "    edges = cv2.Canny(img, 100, 200)\n",
        "    img = cv2.addWeighted(img, 0.8, edges, 0.2, 0)\n",
        "\n",
        "    img = img / 255.0\n",
        "    return (img * 255).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOCQskj2IirR"
      },
      "outputs": [],
      "source": [
        "for split in [\"train\", \"valid\", \"test\"]:\n",
        "    os.makedirs(f\"{processed_dataset_path}/{split}/images\", exist_ok=True)\n",
        "    os.makedirs(f\"{processed_dataset_path}/{split}/labels\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj6NVEmUIUOz",
        "outputId": "7ae930dc-44de-495e-b578-3773d3bb1922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing train images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3651/3651 [01:58<00:00, 30.75it/s]\n",
            "Processing valid images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 348/348 [00:07<00:00, 47.62it/s]\n",
            "Processing test images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 169/169 [00:03<00:00, 50.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Preprocessing complete!\n",
            "âœ… data.yaml created.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "processed_dataset_path = \"BoneFracture_Preprocessed\"\n",
        "\n",
        "for split in [\"train\", \"valid\", \"test\"]:\n",
        "    images_dir = f\"{dataset_path}/{split}/images\"\n",
        "    labels_dir = f\"{dataset_path}/{split}/labels\"\n",
        "    output_images_dir = f\"{processed_dataset_path}/{split}/images\"\n",
        "    output_labels_dir = f\"{processed_dataset_path}/{split}/labels\"\n",
        "\n",
        "    for img_file in tqdm(os.listdir(images_dir), desc=f\"Processing {split} images\"):\n",
        "        img_path = os.path.join(images_dir, img_file)\n",
        "        processed_img = preprocess_image(img_path)\n",
        "        cv2.imwrite(os.path.join(output_images_dir, img_file), processed_img)\n",
        "\n",
        "        label_file = img_file.replace(\".jpg\", \".txt\")\n",
        "        if os.path.exists(os.path.join(labels_dir, label_file)):\n",
        "            shutil.copy(os.path.join(labels_dir, label_file), os.path.join(output_labels_dir, label_file))\n",
        "\n",
        "print(\"âœ… Preprocessing complete!\")\n",
        "\n",
        "yaml_path_fixed = \"data.yaml\"\n",
        "yaml_content = f\"\"\"\n",
        "train: {processed_dataset_path}/train/images\n",
        "val: {processed_dataset_path}/valid/images\n",
        "test: {processed_dataset_path}/test/images\n",
        "\n",
        "nc: 6\n",
        "names: [\"Elbow Positive\", \"Fingers Positive\", \"Forearm Fracture\", \"Humerus Fracture\", \"Shoulder Fracture\", \"Wrist Positive\"]\n",
        "\"\"\"\n",
        "\n",
        "with open(yaml_path_fixed, \"w\") as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"âœ… data.yaml created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CLvFo4dePZb9",
        "outputId": "b2c60817-a47b-4504-881e-94b674df0c7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/datasets/BoneFracture_Preprocessed'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "shutil.move(\"BoneFracture_Preprocessed\", \"/content/datasets/BoneFracture_Preprocessed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##YOLO MODEL"
      ],
      "metadata": {
        "id": "GFDGnng2V_Gl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh2TPA32OcNq",
        "outputId": "15b9f1f7-466d-4a8f-dfb6-0b1272116562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:00<00:00, 56.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.130 ðŸš€ Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=fracture_detector_v1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolo_training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=yolo_training/fracture_detector_v1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 24.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,012,018 parameters, 3,012,002 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 539.7Â±198.6 MB/s, size: 24.3 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/BoneFracture_Preprocessed/train/labels... 3631 images, 1847 backgrounds, 168 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3651/3651 [00:02<00:00, 1278.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1002_png.rf.1feafce607366113c97124dc22d52328.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1002_png.rf.67c46c90c7089ef2ffa40b5fa22e4ad1.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1002_png.rf.c94d11a79032d6beb4ce4d876c9f7fda.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1022_png.rf.077dcb969ab7f549f7bc09bddca07895.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1022_png.rf.8bb506fab5d76213a035adf3069a821c.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1022_png.rf.9fa19d22112cf8bcdc7904294969ab27.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1097_png.rf.15a75fbda4efd74f9622c3e8b37dfdb5.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1097_png.rf.4e5ab3934cf7885facb1e2efd8e0d633.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1097_png.rf.ed98dc5ce0c6c548745c1826185cbe51.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1100_png.rf.b52254839f819b480d546b6a8368b3b2.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1100_png.rf.d8f1f5531744293689292f19b9f67c71.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1100_png.rf.e7f9b2c0515b638bb87c095451702021.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1131_png.rf.0219308e7abe536c2d7e294bedb415d5.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1131_png.rf.6a57c25d2fd242557b8ad2e777c1ddfe.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1131_png.rf.a71671c8040628c841483b319af5bd61.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1159_png.rf.2b5e9a87d8661d5991a2043fbd672d17.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1159_png.rf.69ee947114ea53fa0223c11e05618ac8.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1159_png.rf.87861c45a5bacaf6db92fd5b4119c9ca.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1189_png.rf.0d907ea64f2c2b49b72f8fcff245ce14.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1189_png.rf.cecc214e94a12222c52f678e80a84a1c.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1189_png.rf.e538d3a229ada867f285dad84c25ddb8.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1236_png.rf.3013f8b742fdd76139ea780b3f76d817.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1236_png.rf.4f5aeec40f78f23cda3b3fe43de1dcb0.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1236_png.rf.f9d7455306f807445d56c347239f0fea.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1329_png.rf.7ea2f8ee0840d8b6eec53889e5e35888.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1329_png.rf.9eb293e906e9781607ba6b6666457ed3.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1329_png.rf.c6489369d32e30b33c456f7263867c95.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1330_png.rf.a49bcbd2382665e9c4005bc01c143ec2.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1330_png.rf.b5ca8ef975148a8b5ed06de614621c58.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1330_png.rf.bf0846404346285f22ad00292ed70746.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_134_png.rf.1080629c696b740b736fb941278b1929.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_134_png.rf.36448dea2e59ea504d9db009b87e0752.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_134_png.rf.e813e488767b122fbb73db039fccc5dd.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1377_png.rf.1fddfe35fdc6bae74dcb81f6e430bad7.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1377_png.rf.31686664dc74e4cdb878dd2e7e60a6e9.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1377_png.rf.a771a09b4d018847fd40666aaaef21b1.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1381_png.rf.4270b98c8fc2e53ef2430e99fcefab4c.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1381_png.rf.56ffcabc4df5deedfab9d035dd29b0bf.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1381_png.rf.d9cacce5b9757b34996533ecba4b9aed.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1392_png.rf.06da79e25baca755b454cd65a0fada98.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1392_png.rf.66354eea7feeb1b0cc95d8f6d3a0307b.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1392_png.rf.7831797a45921701b56c91989e3a573a.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1412_png.rf.07322066d34e64a5d729dc408dbb366e.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1412_png.rf.ad120e8d91bb9dc8e46b103909f4f498.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1412_png.rf.c0e68e00ecbdb6c5c6fe3b3bef4d62f0.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1417_png.rf.9b2fc234851c22c20ef6cdd5ba1a5572.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1417_png.rf.d809f1c863c4d73472b22d9d4caefdd5.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1417_png.rf.d9998cc3db123bad6dbc2e2565e16fa9.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1449_png.rf.38aa7e05c825d43ef468897420fc66b2.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1449_png.rf.53afeb9e6afd916e4b737eec6c8f2deb.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1449_png.rf.9c942089af5b6562e9564890fce5bd5a.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1786_png.rf.273397a32fb6a564819a1ca77e5f8e88.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1786_png.rf.8b39b82c026e569b475bb6989373bf82.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1786_png.rf.9f3a33f53195db1bda32cb7aaefae52d.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_180_png.rf.262ad7901380c2894c2c2ed018896880.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_180_png.rf.330904189768fef4e4341174ab1237ff.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_180_png.rf.d5a9205746e7efd2ef5adf49958f1c20.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1830_png.rf.3de271d6402c467ec61f220cc3bc5fd4.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1830_png.rf.808ae1ad8285fd024357cec479326cf5.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1830_png.rf.d48bf27134691077474fe55a7dd26ac5.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1836_png.rf.421e846982a672e8a062aa2ad186d466.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1836_png.rf.5e477b9ca972ad1fa9851e72981324f1.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1836_png.rf.9eaeb12249cfe7cba0c0b8bb3c5b6b4f.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1882_png.rf.3e8a709cdce667a4d0e9e22facaaa609.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1882_png.rf.45462a346fd670264ee43024fee1b212.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1882_png.rf.5a8446e65d39a33d34d8a61483135771.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1906_png.rf.1518f5a2d11edf6175580dd80eefe2b4.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1906_png.rf.9b08a64233d9a9fdbbe2d5426371a217.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1906_png.rf.b7c40489a963550f71a18d9f4012bb24.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1932_png.rf.51db8386d52bfcdb0deda33fc34d52e5.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1932_png.rf.a32bb9cee4fbab2e8c3f77d1e78295f8.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1932_png.rf.bc30a0a88edc82de1d4cdbdbfcb42522.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1986_png.rf.4e89f4edeb2acd832a8345f5862cdb5f.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1986_png.rf.b34348ba439924f264dd5a069d2d1478.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1986_png.rf.d2704ad85f8101bb1def8a6c232bd37f.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1989_png.rf.10ed4a7ef97fa8624615a5e756cc9123.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1989_png.rf.195bebb5a51e04b09e659727ce555acc.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_1989_png.rf.e575a1ad4644afa690de27feaf2fbf0c.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2009_png.rf.11be32b4fe93c9aa38220b4238d46087.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2009_png.rf.445a31141bcd21749bd11399a0c89175.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2009_png.rf.50321591f34a947bcc8d4b7f4f24a2f4.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2048_png.rf.4a22b7231c2ebb67c88daf386f2006b5.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2048_png.rf.c68ef3d00374752e35fde45aa61b0768.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2048_png.rf.dc27efeaa98858fb15e440491e0ad923.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2131_png.rf.2f92abf79250dd099557799ea8e20ffd.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2131_png.rf.3046a6ddff2f6526694c712374af0c54.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2131_png.rf.6786c5be4d16bda8b6c2e25dd0c3efad.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2136_png.rf.15a345b5230876f6d9d2d021039f1c08.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2136_png.rf.80c9e7df0f1a56cef5efa3543c126357.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2136_png.rf.9aae0d52132e74a5c1e10c45a583ae0c.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2151_png.rf.6aa6ec00dfd8020e2f8f34a61f96df97.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2151_png.rf.be27df8b1c3469ff4ebf432e9132ee4b.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2151_png.rf.cff239037cfe6ab93b44373053e9624b.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2168_png.rf.154bb43bcf761fed537cb27caecbbac7.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2168_png.rf.3c848a68aacdb1ec062a275b06c5935d.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2168_png.rf.836d3b393693b6c6013f0fe63d2b9b99.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2176_png.rf.34437001c100ff07a2aeec59208b7677.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2176_png.rf.5b792a5c2bd30d0d8565a61942486a37.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2176_png.rf.c7e79c99d1dea275b6451d4926683493.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2181_png.rf.5da98a62be9cf0adb9b860c5a27c586d.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2181_png.rf.5db96c18b523e701a53f1442fbf53314.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2181_png.rf.f9a3beda714438f080b77ea767e7ffdf.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_220_png.rf.02a2decb0199433c13df58d383de0837.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_220_png.rf.43cb0deb6e2b52e0bda8cb3e07bc851e.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_220_png.rf.a4835870416348243828cd7240d5f0dd.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2212_png.rf.0e8801a661b7da83c8eada7c2368a10d.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2212_png.rf.74d1f90abd82a745c76e37eb86611d38.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2212_png.rf.b9551b802e6a643bd87f1c2b5a170224.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2228_png.rf.8183072cec786e892d51e90c396300b2.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2228_png.rf.955c60256deb83f51650c47fcdb859f6.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2228_png.rf.b120e8c9b23a9868d8ed3d70a7b85194.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2257_png.rf.615eb68c8fb57528d0d416d8737711a8.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2257_png.rf.acbb8ed381e14f39b34b50640db90568.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2257_png.rf.b17248adc86bb3f935622c7b5ad62f87.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2281_png.rf.222225211cfa1557d967a025b2a9571c.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2281_png.rf.3ea142e50b873f88d641362ae870df92.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2281_png.rf.771c31b7d780b7303aa654e785dcff7e.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2288_png.rf.05c60719759b92050297528ebecbc774.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2288_png.rf.39b2426887c3af288d1628f65629d3e3.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2288_png.rf.ec6b20c65588871c3ce9d8a762e64109.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2303_png.rf.5b6f803e437abdde8cc23ccebc2ab108.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2303_png.rf.b03b2a6a9c112a8ab71d73ac6a2430b7.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2303_png.rf.bceb3ca9587bb0a30486ca18712f1055.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2343_png.rf.2a32bfe779f56226a493cc4afda28fe7.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2343_png.rf.4f119e2b5a7c01b8cc9c972e41d1c2ae.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2343_png.rf.d5c384d41d61edf8d915087757d8b557.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2355_png.rf.43ccd043131f32339f66c35fd3ea3b79.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2355_png.rf.47942fd56f27dc90ac623b6b653b057b.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2355_png.rf.ae122186c744b7fb496a08f076c339ed.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2394_png.rf.416c9c3598e6bdec48d8ad264e1586e2.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2394_png.rf.7e9775c85746eb339f59967431f19d8f.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2394_png.rf.e12fc3f9f5f48a5733b4928d70b5002a.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2420_png.rf.25028917c0f60f10817d50c18c4d7db2.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2420_png.rf.59d880bd5cb53b4f7907c4896684ea45.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2420_png.rf.de2ac32a28bbd151e9a6aa01187c0311.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2426_png.rf.0450e051d604067ab09b34fa9c6ba11e.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2426_png.rf.ae3d45a0ca3104d5ad930c1a16a8b960.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2426_png.rf.db715606e177dabf45ea34b05f8b54aa.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2466_png.rf.35b6464356210089ebb3c6c018993d56.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2466_png.rf.66ada4bb5a47581d9b4c0303f20488c2.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2466_png.rf.f5a16c2b9a86dcaa77bb9bf9d49f6d45.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2467_png.rf.21a67073459ebdc24359d8d955f1e454.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2467_png.rf.96310ecbbd48d4474777e00692deaf4f.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2467_png.rf.a4c002636960787ffe6f40aa76b69c75.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2476_png.rf.07cc92b6da497f29cdcb434ac0cafca8.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2476_png.rf.1c44fdf3ce983524ca83fd5cdfae3a2e.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2476_png.rf.72dd25a762a3ff7372c9f78dc5c6dea5.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2483_png.rf.02bc16ff1ced5b128e5cb22120ec7e48.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2483_png.rf.1df81b9e25c1da7da9f371229b073881.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2483_png.rf.379ce27e9e681fd36eca35cb7c458085.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2500_png.rf.ba22f8a5436b9e57543835d304d7e435.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2500_png.rf.ee4f224f5613fe553ee0454c0bf07195.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2500_png.rf.f1aaa9fe49fb1ccb1f6187805c506f6c.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2514_png.rf.1472ee69aa2587e2fe7ebc45bfe689b1.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2514_png.rf.c3a391c7b9beca91a66c656e0cdd9955.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2514_png.rf.d22f36933ae24eb61c71db235f158f62.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2524_png.rf.391131ab08cf2fbfecd4d3763a4a2f5b.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2524_png.rf.8ad3e2634b51627c2e52447d38acbeef.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2524_png.rf.df8e4faa39fea1f9216316ed7a9ba466.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2600_png.rf.52faceed1855459018c21b4f74b58d25.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2600_png.rf.9d1e05ab0c3fe836ecb07bbe953195f6.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2600_png.rf.d01cf2a3a437207bcb1fb65bc0295e4d.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_265_png.rf.a4c7a70a39569def18e79217a8af2b78.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_265_png.rf.dce2946a581c141d6c7a3df584b001f3.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_265_png.rf.f6b4f2239f56521e1e039bc20acad84e.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2740_png.rf.55f47c6e21eb155deb34a40055aa1b4c.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2740_png.rf.693ef72ac5f8eccd3f08283d811862bd.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/datasets/BoneFracture_Preprocessed/train/images/image1_2740_png.rf.adef408be2861b803863f2af7bbc6611.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/BoneFracture_Preprocessed/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 549.2Â±244.5 MB/s, size: 21.2 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/BoneFracture_Preprocessed/valid/labels... 348 images, 175 backgrounds, 17 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 348/348 [00:00<00:00, 1898.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/BoneFracture_Preprocessed/valid/images/image1_1090_png.rf.de645f822a5e36175c5e988223f4eeb0.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/BoneFracture_Preprocessed/valid/images/image1_111_png.rf.3893d8f7588cea4d796d26119e52637f.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/BoneFracture_Preprocessed/valid/images/image1_119_png.rf.77de12cb566fc295603927e2a5b2748a.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/BoneFracture_Preprocessed/valid/images/image1_1310_png.rf.daf759fe071a5733142e9847fb388e75.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/BoneFracture_Preprocessed/valid/images/image1_1802_png.rf.ada9b0ad89e89af07a36ed5590773b7e.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/BoneFracture_Preprocessed/valid/images/image1_1900_png.rf.b5bcead0522f3d8b2bee79cc15a5477f.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/BoneFracture_Preprocessed/valid/images/image1_1992_png.rf.379b87658e6c985d51218b5383d5450b.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/BoneFracture_Preprocessed/valid/images/image1_2027_png.rf.d64c9d07c29a2c6b7b76b6df9f8933e5.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/BoneFracture_Preprocessed/valid/images/image1_2062_png.rf.96caca3e4789f028ac1329ea33773425.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/BoneFracture_Preprocessed/valid/images/image1_2128_png.rf.f8b6cd5da365cf54ad4c51ff43bcb9bf.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/BoneFracture_Preprocessed/valid/images/image1_213_png.rf.85241ed9c6ce96f4a18e85ec6482b246.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/BoneFracture_Preprocessed/valid/images/image1_2145_png.rf.a47b00248c5acbae164fa4f06f39861b.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/BoneFracture_Preprocessed/valid/images/image1_2193_png.rf.9f98385cf14495eb548024eeca646222.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/BoneFracture_Preprocessed/valid/images/image1_2291_png.rf.62cfeef40c65e7f1fe873335c535e13d.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/BoneFracture_Preprocessed/valid/images/image1_2487_png.rf.d44e02e62692a0c9e37bdcfc4ef78003.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/BoneFracture_Preprocessed/valid/images/image1_2552_png.rf.7a87da3fa8c3d03f97c51bcec0ead7e7.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/datasets/BoneFracture_Preprocessed/valid/images/image1_2648_png.rf.c61d3b5957667c312078bb290f1fcc9e.jpg: ignoring corrupt image/label: Label class 6 exceeds dataset class count 6. Possible class labels are 0-5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/BoneFracture_Preprocessed/valid/labels.cache\n",
            "Plotting labels to yolo_training/fracture_detector_v1/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1myolo_training/fracture_detector_v1\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50         0G      2.829      7.013      2.303          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 436/436 [46:38<00:00,  6.42s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:26<00:00,  4.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        331        176   0.000311      0.121    0.00606   0.000759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50         0G      2.633      4.921      2.176          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 436/436 [47:04<00:00,  6.48s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:27<00:00,  4.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        331        176       0.65     0.0204     0.0147    0.00404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50         0G      2.584        4.3      2.129         11        640:  15%|â–ˆâ–Œ        | 66/436 [07:10<39:42,  6.44s/it]"
          ]
        }
      ],
      "source": [
        "model = YOLO(\"yolov8n.pt\")\n",
        "model.train(\n",
        "    data=yaml_path_fixed,\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=8,\n",
        "    workers=4,\n",
        "    project=\"yolo_training\",\n",
        "    name=\"fracture_detector_v1\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "import time\n",
        "for i in range(120):\n",
        "    print(f\"âš¡ Training in progress... heartbeat {i+1}\")\n",
        "    time.sleep(240)\n",
        "\n",
        "\n",
        "\n",
        "test_data_path = \"/kaggle/input/test-data\"\n",
        "results = model.predict(source=test_data_path, save=True, save_txt=True, conf=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SKGkCb1SV5so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "PvIv0FRLV5hW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "UrYc9EdgIYtr",
        "outputId": "76e7efd2-dc22-41e4-d516-c52c02b35ddf"
      },
      "outputs": [
        {
          "ename": "DisabledFunctionError",
          "evalue": "cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDisabledFunctionError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b06566c6b5a6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Check if the label file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mdraw_bounding_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Annotation complete!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-b06566c6b5a6>\u001b[0m in \u001b[0;36mdraw_bounding_boxes\u001b[0;34m(image_path, label_path)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotated_image_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotated_image_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Annotated Image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_import_hooks/_cv2.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisabledFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDisabledFunctionError\u001b[0m: cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Function to draw bounding boxes\n",
        "def draw_bounding_boxes(image_path, label_path):\n",
        "    # Read the image\n",
        "    image = cv2.imread(image_path)\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Open the label file\n",
        "    with open(label_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # Draw each bounding box\n",
        "    for line in lines:\n",
        "        # Each line in the label file corresponds to a bounding box\n",
        "        parts = line.strip().split()\n",
        "        class_id = int(parts[0])  # class_id (not really needed, but can be useful)\n",
        "        x_center = float(parts[1])\n",
        "        y_center = float(parts[2])\n",
        "        box_width = float(parts[3])\n",
        "        box_height = float(parts[4])\n",
        "\n",
        "        # Convert normalized coordinates to pixel values\n",
        "        x_min = int((x_center - box_width / 2) * width)\n",
        "        y_min = int((y_center - box_height / 2) * height)\n",
        "        x_max = int((x_center + box_width / 2) * width)\n",
        "        y_max = int((y_center + box_height / 2) * height)\n",
        "\n",
        "        # Draw the bounding box on the image\n",
        "        color = (0, 255, 0)  # Green color for the box\n",
        "        thickness = 2  # Thickness of the bounding box\n",
        "        image = cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color, thickness)\n",
        "\n",
        "    # Save or show the image with annotations\n",
        "    annotated_image_path = image_path.replace(\"img\", \"annotated_img\")  # Save to annotated_img folder\n",
        "    os.makedirs(os.path.dirname(annotated_image_path), exist_ok=True)\n",
        "    cv2.imwrite(annotated_image_path, image)\n",
        "    cv2.imshow(\"Annotated Image\", image)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Directory paths (adjust as needed)\n",
        "image_folder = dataset_path+'train/images'  # e.g.\n",
        "label_folder = dataset_path+'train/labels' # e.g.\n",
        "\n",
        "for img_filename in os.listdir(image_folder):\n",
        "    if img_filename.endswith('.jpg') or img_filename.endswith('.png'):\n",
        "        image_path = os.path.join(image_folder, img_filename)\n",
        "        label_path = os.path.join(label_folder, img_filename.replace('.jpg', '.txt').replace('.png', '.txt'))\n",
        "\n",
        "        # Check if the label file exists\n",
        "        if os.path.exists(label_path):\n",
        "            draw_bounding_boxes(image_path, label_path)\n",
        "\n",
        "print(\"Annotation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "YiEKU3AuJFQX",
        "outputId": "6dec8939-2cdd-4b4a-e808-bb14b1f070d4"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'image_paths' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2ac777abe8a4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_and_preprocess_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'image_paths' is not defined"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def load_and_preprocess_image(path, label):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_image(img)\n",
        "    img = tf.image.resize(img, [64, 64])\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
        "dataset = dataset.map(load_and_preprocess_image)\n",
        "dataset = dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKjVMm71jHnJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import os\n",
        "def load_data(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for label_file in os.listdir(data_dir + '/labels'):\n",
        "        img_filename = label_file.replace('.txt', '.jpg')\n",
        "        img_path = os.path.join(data_dir, 'images', img_filename)\n",
        "\n",
        "        if os.path.exists(img_path):\n",
        "            with open(os.path.join(data_dir, 'labels', label_file), 'r') as f:\n",
        "                label_data = f.readlines()\n",
        "\n",
        "            bbox_list = []\n",
        "            for line in label_data:\n",
        "                values = list(map(float, line.strip().split()))\n",
        "                bbox_list.append(values)  # Assuming they are in [class, x_center, y_center, width, height]\n",
        "\n",
        "            images.append(tf.io.read_file(img_path))\n",
        "            # Ensure the bounding boxes are in the correct format\n",
        "            labels.append(tf.convert_to_tensor(bbox_list, dtype=tf.float32))\n",
        "        else:\n",
        "            print(f\"Image not found: {img_path}\")\n",
        "\n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gk9rwznmCq5"
      },
      "outputs": [],
      "source": [
        "\n",
        "def preprocess_image(image):\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    image = image / 255.0\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ws5C6c9EmGQ_"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "\n",
        "def map_func(image, label):\n",
        "    return preprocess_image(image), label  # Keep label as tensor\n",
        "\n",
        "train_dataset = train_dataset.map(map_func).batch(32).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wpmxnp0tmWGC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    # Output layer for bounding boxes [x_center, y_center, width, height]\n",
        "    tf.keras.layers.Dense(4, activation='sigmoid')  # Adjust for your output\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5bI0zUxnO21"
      },
      "outputs": [],
      "source": [
        "\n",
        "def custom_loss(y_true, y_pred):\n",
        "    # Adjust for multiple bounding boxes\n",
        "    return tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)  # Calculate loss per bounding box"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "oQWbEKcYoWjY",
        "outputId": "4749e607-691d-4aa9-bac7-3afbfec4614d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Dimensions must be equal, but are 0 and 4 for '{{node compile_loss/custom_loss/sub}} = Sub[T=DT_FLOAT](data_1, sequential_2_1/dense_6_1/Sigmoid)' with input shapes: [?,0], [?,4].",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-215e4e7aa517>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-53bd9529e062>\u001b[0m in \u001b[0;36mcustom_loss\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcustom_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Adjust for multiple bounding boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Calculate loss per bounding box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 0 and 4 for '{{node compile_loss/custom_loss/sub}} = Sub[T=DT_FLOAT](data_1, sequential_2_1/dense_6_1/Sigmoid)' with input shapes: [?,0], [?,4]."
          ]
        }
      ],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "\n",
        "def map_func(image, label):\n",
        "    return preprocess_image(image), tf.convert_to_tensor(label, dtype=tf.float32)\n",
        "\n",
        "train_dataset = train_dataset.map(map_func).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "model.compile(optimizer='adam', loss=custom_loss)\n",
        "model.fit(train_dataset, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gqh9ZYBYocmJ"
      },
      "outputs": [],
      "source": [
        "num_boxes = 5  # Example: Adjust this based on your dataset\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    # Output layer for multiple bounding boxes\n",
        "    tf.keras.layers.Dense(num_boxes * 4, activation='sigmoid'),  # Flattened output\n",
        "    tf.keras.layers.Reshape((num_boxes, 4))  # Reshape to (num_boxes, 4)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-3rXS3QpUfM"
      },
      "outputs": [],
      "source": [
        "def load_data(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for label_file in os.listdir(data_dir + '/labels'):\n",
        "        img_filename = label_file.replace('.txt', '.jpg')\n",
        "        img_path = os.path.join(data_dir, 'images', img_filename)\n",
        "\n",
        "        if os.path.exists(img_path):\n",
        "            with open(os.path.join(data_dir, 'labels', label_file), 'r') as f:\n",
        "                label_data = f.readlines()\n",
        "\n",
        "            bbox_list = []\n",
        "            for line in label_data:\n",
        "                values = list(map(float, line.strip().split()))\n",
        "                bbox_list.append(values)  # Assuming they are in [x_center, y_center, width, height]\n",
        "\n",
        "            # Pad or truncate the bbox_list to match num_boxes\n",
        "            while len(bbox_list) < num_boxes:\n",
        "                bbox_list.append([0, 0, 0, 0])  # Padding with zeros\n",
        "            bbox_list = bbox_list[:num_boxes]  # Truncate if necessary\n",
        "\n",
        "            images.append(tf.io.read_file(img_path))\n",
        "            labels.append(tf.convert_to_tensor(bbox_list, dtype=tf.float32))\n",
        "        else:\n",
        "            print(f\"Image not found: {img_path}\")\n",
        "\n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "0dgCfmj_pXKT",
        "outputId": "9552681e-1452-447d-b6b8-ec81d752f2a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Dimensions must be equal, but are 0 and 4 for '{{node compile_loss/custom_loss/sub}} = Sub[T=DT_FLOAT](data_1, sequential_3_1/reshape_1/Reshape)' with input shapes: [?,0], [?,5,4].",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-4b00d3a6f07b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Fit the model to the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust the number of epochs as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-53bd9529e062>\u001b[0m in \u001b[0;36mcustom_loss\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcustom_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Adjust for multiple bounding boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Calculate loss per bounding box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 0 and 4 for '{{node compile_loss/custom_loss/sub}} = Sub[T=DT_FLOAT](data_1, sequential_3_1/reshape_1/Reshape)' with input shapes: [?,0], [?,5,4]."
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='adam', loss=custom_loss)\n",
        "\n",
        "# Fit the model to the dataset\n",
        "model.fit(train_dataset, epochs=10)  # Adjust the number of epochs as needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "Bjvb-zvCpd3F",
        "outputId": "864ef2bd-20a1-4aab-f107-9c53ca9ac59d"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'path/to/your/data/labels'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-a249d98a7463>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'path/to/your/data'\u001b[0m  \u001b[0;31m# Update this to your data directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# Prepare dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-a249d98a7463>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mimg_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/your/data/labels'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Constants\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH = 224, 224\n",
        "NUM_BOXES = 5  # Adjust based on your dataset\n",
        "\n",
        "# Data loading function\n",
        "def load_data(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for label_file in os.listdir(os.path.join(data_dir, 'labels')):\n",
        "        img_filename = label_file.replace('.txt', '.jpg')\n",
        "        img_path = os.path.join(data_dir, 'images', img_filename)\n",
        "\n",
        "        if os.path.exists(img_path):\n",
        "            with open(os.path.join(data_dir, 'labels', label_file), 'r') as f:\n",
        "                label_data = f.readlines()\n",
        "\n",
        "            bbox_list = []\n",
        "            for line in label_data:\n",
        "                values = list(map(float, line.strip().split()))\n",
        "                bbox_list.append(values)  # Assuming [x_center, y_center, width, height]\n",
        "\n",
        "            # Pad or truncate to fit NUM_BOXES\n",
        "            while len(bbox_list) < NUM_BOXES:\n",
        "                bbox_list.append([0, 0, 0, 0])  # Padding\n",
        "            bbox_list = bbox_list[:NUM_BOXES]  # Truncate if necessary\n",
        "\n",
        "            images.append(tf.io.read_file(img_path))\n",
        "            labels.append(tf.convert_to_tensor(bbox_list, dtype=tf.float32))\n",
        "        else:\n",
        "            print(f\"Image not found: {img_path}\")\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# Preprocessing function (customize as needed)\n",
        "def preprocess_image(image):\n",
        "    img = tf.image.decode_jpeg(image, channels=3)\n",
        "    img = tf.image.resize(img, [IMAGE_HEIGHT, IMAGE_WIDTH])\n",
        "    img = img / 255.0  # Normalize to [0, 1]\n",
        "    return img\n",
        "\n",
        "# Custom loss function\n",
        "def custom_loss(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.square(y_true - y_pred), axis=[1, 2])  # Average over boxes and batches\n",
        "\n",
        "# Model definition\n",
        "def create_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(NUM_BOXES * 4, activation='sigmoid'),  # Output layer\n",
        "        tf.keras.layers.Reshape((NUM_BOXES, 4))  # Reshape to (NUM_BOXES, 4)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    data_dir = dataset_path+'train/'  # Update this to your data directory\n",
        "    train_images, train_labels = load_data(data_dir)\n",
        "\n",
        "    # Prepare dataset\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "    train_dataset = train_dataset.map(lambda img, lbl: (preprocess_image(img), lbl)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    # Create and compile the model\n",
        "    model = create_model()\n",
        "    model.compile(optimizer='adam', loss=custom_loss)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_dataset, epochs=10)\n",
        "\n",
        "    # Save the model\n",
        "    model.save('my_object_detection_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "nbXrxAP1pqk0",
        "outputId": "0837608b-0d8a-4970-e356-4922f00dfa1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_3123_png.rf.cc421f7578cef1c5eae31ed403f3350b (1).jpg\n",
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_191_png.rf.4281c0740362e3f7870d931d1e405aab (1).jpg\n",
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_309_png.rf.acab65f10f04644c5e615777d54e4fa2 (1).jpg\n",
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_190_png.rf.f91841e6b0b9082579f5cbcfd290182d (1).jpg\n",
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_1932_png.rf.bc30a0a88edc82de1d4cdbdbfcb42522 (1).jpg\n",
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_30_png.rf.365839c48a61141f1c1c96ccc9c02fa3 (1).jpg\n",
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_191_png.rf.d0add82fd21e8d5ab536203d84864836 (1).jpg\n",
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_191_png.rf.b5bca4e7ef61690aa61086c3e70ef1e6 (1).jpg\n",
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_311_png.rf.a37120e1d235915917ee37f706e7e707 (1).jpg\n",
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_191_png.rf.b2d6ba2bd91ff388b38236071e2e8ea9 (1).jpg\n",
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_191_png.rf.c54d282c0bdbb3f46003ceda29a4ee91 (1).jpg\n",
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_3123_png.rf.d46a4883d73d47b5cea4f005f4338c41 (1).jpg\n",
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_309_png.rf.a3898a8dfa8077dce4fff094b1e270b6 (1).jpg\n",
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_30_png.rf.0da06c06bb491a89bebb9622a6dd1d0f (1).jpg\n",
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_1932_png.rf.a32bb9cee4fbab2e8c3f77d1e78295f8 (1).jpg\n",
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_191_png.rf.f260cb873073255c698511d40ad0d2d7 (1).jpg\n",
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_30_png.rf.260306daac033c8e16ddcf6063b480db (1).jpg\n",
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_311_png.rf.773ac4d2c98ed57c2e44e8423b9a44cc (1).jpg\n",
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_1932_png.rf.51db8386d52bfcdb0deda33fc34d52e5 (1).jpg\n",
            "Image not found: /content/drive/MyDrive/bonesfracrion/bone fracture detection.v4-v4.yolov8/train/images/image1_311_png.rf.5dec40fd2d5b17aab524be0a3066fe1d (1).jpg\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Can't convert non-rectangular Python sequence to Tensor.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-4da982cff3e8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'train/'\u001b[0m  \u001b[0;31m# Update this to your data directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# Prepare dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-4da982cff3e8>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Convert lists to tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Images as string tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Labels as float tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Can't convert non-rectangular Python sequence to Tensor."
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Constants\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH = 224, 224\n",
        "NUM_BOXES = 5  # Adjust based on your dataset\n",
        "\n",
        "# Data loading function\n",
        "def load_data(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for label_file in os.listdir(os.path.join(data_dir, 'labels')):\n",
        "        img_filename = label_file.replace('.txt', '.jpg')\n",
        "        img_path = os.path.join(data_dir, 'images', img_filename)\n",
        "\n",
        "        if os.path.exists(img_path):\n",
        "            with open(os.path.join(data_dir, 'labels', label_file), 'r') as f:\n",
        "                label_data = f.readlines()\n",
        "\n",
        "            bbox_list = []\n",
        "            for line in label_data:\n",
        "                values = list(map(float, line.strip().split()))\n",
        "                bbox_list.append(values)\n",
        "\n",
        "\n",
        "            while len(bbox_list) < NUM_BOXES:\n",
        "                bbox_list.append([0, 0, 0, 0])  # Padding with zeros\n",
        "            bbox_list = bbox_list[:NUM_BOXES]  # Truncate if necessary\n",
        "\n",
        "            images.append(tf.io.read_file(img_path))\n",
        "            labels.append(bbox_list)\n",
        "        else:\n",
        "            print(f\"Image not found: {img_path}\")\n",
        "\n",
        "\n",
        "    images = tf.convert_to_tensor(images, dtype=tf.string)  # Images as string tensors\n",
        "    labels = tf.convert_to_tensor(labels, dtype=tf.float32)  # Labels as float tensors\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# Preprocessing function (customize as needed)\n",
        "def preprocess_image(image):\n",
        "    img = tf.image.decode_jpeg(image, channels=3)\n",
        "    img = tf.image.resize(img, [IMAGE_HEIGHT, IMAGE_WIDTH])\n",
        "    img = img / 255.0  # Normalize to [0, 1]\n",
        "    return img\n",
        "\n",
        "# Custom loss function\n",
        "def custom_loss(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.square(y_true - y_pred), axis=[1, 2])  # Average over boxes and batches\n",
        "\n",
        "# Model definition\n",
        "def create_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(NUM_BOXES * 4, activation='sigmoid'),  # Output layer\n",
        "        tf.keras.layers.Reshape((NUM_BOXES, 4))  # Reshape to (NUM_BOXES, 4)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    data_dir = dataset_path+'train/'  # Update this to your data directory\n",
        "    train_images, train_labels = load_data(data_dir)\n",
        "\n",
        "    # Prepare dataset\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "    train_dataset = train_dataset.map(lambda img, lbl: (preprocess_image(img), lbl)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    # Create and compile the model\n",
        "    model = create_model()\n",
        "    model.compile(optimizer='adam', loss=custom_loss)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_dataset, epochs=10)\n",
        "\n",
        "    # Save the model\n",
        "    model.save('my_object_detection_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4daVm-uqNu8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMP3IA6e3iQh6qxOfdJvEzS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}